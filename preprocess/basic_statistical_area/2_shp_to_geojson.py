#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°‡ Shapefile è½‰æ›ç‚º GeoJSON æ ¼å¼
"""

import geopandas as gpd
import pandas as pd
import json
from pathlib import Path
import chardet
import warnings
import sys
import locale

warnings.filterwarnings('ignore')

# è¨­å®šç·¨ç¢¼
sys.stdout.reconfigure(encoding='utf-8')
locale.setlocale(locale.LC_ALL, '')


def detect_encoding(file_path):
    """æª¢æ¸¬æª”æ¡ˆç·¨ç¢¼"""
    try:
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            result = chardet.detect(raw_data)
            return result['encoding']
    except Exception as e:
        print(f"ç·¨ç¢¼æª¢æ¸¬å¤±æ•—: {e}")
        return None


def read_shapefile_with_encoding(shp_path):
    """å˜—è©¦ä½¿ç”¨ä¸åŒç·¨ç¢¼è®€å– shapefile"""

    # å¦‚æœæ˜¯è³‡æ–™å¤¾ï¼Œæ‰¾åˆ° .shp æª”æ¡ˆï¼ˆæ”¯æ´å¤§å°å¯«ï¼‰
    if Path(shp_path).is_dir():
        # å…ˆå˜—è©¦å°å¯«
        shp_files = list(Path(shp_path).glob('*.shp'))
        # å¦‚æœæ²’æ‰¾åˆ°ï¼Œå˜—è©¦å¤§å¯«
        if not shp_files:
            shp_files = list(Path(shp_path).glob('*.SHP'))

        if shp_files:
            shp_path = str(shp_files[0])
            print(f"æ‰¾åˆ° shapefile: {shp_path}")
        else:
            # åˆ—å‡ºè³‡æ–™å¤¾å…§å®¹ä»¥ä¾¿é™¤éŒ¯
            all_files = list(Path(shp_path).glob('*'))
            file_list = [f.name for f in all_files]
            raise Exception(f"åœ¨è³‡æ–™å¤¾ {shp_path} ä¸­æ‰¾ä¸åˆ° .shp æˆ– .SHP æª”æ¡ˆã€‚æ‰¾åˆ°çš„æª”æ¡ˆ: {file_list}")

    # å¸¸è¦‹çš„ç·¨ç¢¼åˆ—è¡¨ï¼ˆé‡å°å°ç£åœ°å€ï¼‰
    encodings = [
        'utf-8',
        'cp950',      # Windows ç¹é«”ä¸­æ–‡
        'big5',       # Big5 ç¹é«”ä¸­æ–‡
        'big5hkscs',  # Big5 é¦™æ¸¯å¢è£œå­—ç¬¦é›†
        'gbk',        # ç°¡é«”ä¸­æ–‡
        'gb2312',
        'gb18030',
        'latin1',
        'iso-8859-1',
        'windows-1252',
        'cp1252'
    ]

    # æª¢æ¸¬ .dbf æª”æ¡ˆç·¨ç¢¼ï¼ˆæ”¯æ´å¤§å°å¯«ï¼‰
    dbf_path_lower = shp_path.replace('.shp', '.dbf').replace('.SHP', '.dbf')
    dbf_path_upper = shp_path.replace('.shp', '.DBF').replace('.SHP', '.DBF')

    dbf_path = None
    if Path(dbf_path_lower).exists():
        dbf_path = dbf_path_lower
    elif Path(dbf_path_upper).exists():
        dbf_path = dbf_path_upper

    if dbf_path:
        print(f"æ‰¾åˆ° DBF æª”æ¡ˆ: {dbf_path}")
        detected = detect_encoding(dbf_path)
        if detected and detected.lower() not in [enc.lower() for enc in encodings]:
            encodings.insert(0, detected)
            print(f"æª¢æ¸¬åˆ°ç·¨ç¢¼: {detected}")

    # å˜—è©¦ä¸åŒç·¨ç¢¼
    last_error = None
    for encoding in encodings:
        try:
            print(f"å˜—è©¦ç·¨ç¢¼: {encoding}")
            gdf = gpd.read_file(shp_path, encoding=encoding)

            # æª¢æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡å­—ç¬¦èƒ½æ­£ç¢ºé¡¯ç¤º
            for col in gdf.columns:
                if col != 'geometry' and gdf[col].dtype == 'object':
                    sample = gdf[col].dropna().iloc[0] if len(gdf[col].dropna()) > 0 else ""
                    if sample:
                        # å˜—è©¦é¡¯ç¤ºæ¨£æœ¬ä¾†é©—è­‰ç·¨ç¢¼
                        print(f"æ¨£æœ¬è³‡æ–™ ({col}): {sample}")
                        break

            print(f"âœ“ æˆåŠŸä½¿ç”¨ç·¨ç¢¼ {encoding} è®€å– shapefile")
            return gdf, encoding

        except Exception as e:
            last_error = e
            print(f"âœ— ç·¨ç¢¼ {encoding} å¤±æ•—: {str(e)[:100]}")
            continue

    # å¦‚æœéƒ½å¤±æ•—ï¼Œå˜—è©¦ä¸æŒ‡å®šç·¨ç¢¼
    try:
        print("å˜—è©¦é è¨­ç·¨ç¢¼...")
        gdf = gpd.read_file(shp_path)
        print("âœ“ æˆåŠŸä½¿ç”¨é è¨­ç·¨ç¢¼")
        return gdf, 'default'
    except Exception as e:
        raise Exception(f"ç„¡æ³•è®€å– shapefileï¼Œæœ€å¾ŒéŒ¯èª¤: {last_error}")


def load_csv_data(csv_paths):
    """
    è¼‰å…¥ CSV è³‡æ–™ä¸¦å»ºç«‹ä»¥ CODEBASE ç‚ºç´¢å¼•çš„å­—å…¸

    Parameters:
    -----------
    csv_paths : dict
        åŒ…å« 'population' å’Œ 'indicators' éµçš„å­—å…¸ï¼Œå°æ‡‰å„ CSV æª”æ¡ˆè·¯å¾‘

    Returns:
    --------
    dict : ä»¥ CODEBASE ç‚ºéµçš„è³‡æ–™å­—å…¸
    """
    print(f"\nğŸ“Š æ­£åœ¨è®€å– CSV è³‡æ–™...")

    # è®€å–äººå£çµ±è¨ˆ CSVï¼ˆæˆ¶æ•¸ã€äººå£æ•¸ï¼‰
    pop_df = pd.read_csv(csv_paths['population'], encoding='utf-8-sig')
    print(f"   âœ… å·²è®€å–äººå£çµ±è¨ˆè³‡æ–™: {len(pop_df)} ç­†")

    # è®€å–äººå£æŒ‡æ¨™ CSVï¼ˆäººå£å¯†åº¦ã€æˆ¶é‡ï¼‰
    ind_df = pd.read_csv(csv_paths['indicators'], encoding='utf-8-sig')
    print(f"   âœ… å·²è®€å–äººå£æŒ‡æ¨™è³‡æ–™: {len(ind_df)} ç­†")

    # å»ºç«‹è³‡æ–™å­—å…¸
    data_dict = {}

    # åˆä½µå…©å€‹ DataFrame
    for _, row in pop_df.iterrows():
        codebase = row['CODEBASE']
        data_dict[codebase] = {
            'H_CNT': row['H_CNT'],      # æˆ¶æ•¸
            'P_CNT': row['P_CNT'],      # äººå£æ•¸
            'M_CNT': row['M_CNT'],      # ç”·æ€§äººå£æ•¸
            'F_CNT': row['F_CNT']       # å¥³æ€§äººå£æ•¸
        }

    # åŠ å…¥äººå£æŒ‡æ¨™è³‡æ–™
    for _, row in ind_df.iterrows():
        codebase = row['CODEBASE']
        if codebase in data_dict:
            data_dict[codebase].update({
                'P_DEN': row['P_DEN'],      # äººå£å¯†åº¦
                'P_H_CNT': row['P_H_CNT'],  # æˆ¶é‡ï¼ˆå¹³å‡æ¯æˆ¶äººæ•¸ï¼‰
                'M_F_RAT': row['M_F_RAT']   # æ€§æ¯”ä¾‹
            })

    print(f"   âœ… å·²å»ºç«‹ {len(data_dict)} å€‹çµ±è¨ˆå€çš„è³‡æ–™å­—å…¸\n")

    return data_dict


def shp_to_geojson(shp_path, output_path, csv_paths=None, compress=True):
    """
    å°‡ Shapefile è½‰æ›ç‚º GeoJSONï¼Œä¸¦åŠ å…¥ CSV è³‡æ–™

    Parameters:
    -----------
    shp_path : str
        Shapefile è³‡æ–™å¤¾è·¯å¾‘æˆ– .shp æª”æ¡ˆè·¯å¾‘
    output_path : str
        è¼¸å‡ºçš„ GeoJSON æª”æ¡ˆè·¯å¾‘
    csv_paths : dict, optional
        åŒ…å« 'population' å’Œ 'indicators' éµçš„å­—å…¸ï¼Œå°æ‡‰å„ CSV æª”æ¡ˆè·¯å¾‘
    compress : bool
        æ˜¯å¦å£“ç¸®è¼¸å‡ºï¼ˆç§»é™¤ç©ºç™½å’Œç¸®æ’ï¼‰
    """

    print(f"æ­£åœ¨è®€å– Shapefile: {shp_path}")
    print("-" * 50)

    # è¼‰å…¥ CSV è³‡æ–™ï¼ˆå¦‚æœæœ‰æä¾›ï¼‰
    csv_data = None
    if csv_paths:
        csv_data = load_csv_data(csv_paths)

    # è®€å– shapefile
    gdf, encoding = read_shapefile_with_encoding(shp_path)

    # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š
    print(f"\nğŸ“„ åŸºæœ¬è³‡è¨Š:")
    print(f"   ä½¿ç”¨ç·¨ç¢¼: {encoding}")
    print(f"   è³‡æ–™ç­†æ•¸: {len(gdf):,}")
    print(f"   åº§æ¨™ç³»çµ±: {gdf.crs}")
    print(f"   å¹¾ä½•é¡å‹: {gdf.geometry.type.value_counts().to_dict()}")

    # é¡¯ç¤ºæ¬„ä½è³‡è¨Š
    print(f"\nğŸ“Š æ¬„ä½è³‡è¨Š:")
    for col in gdf.columns:
        if col != 'geometry':
            dtype = gdf[col].dtype
            unique_count = gdf[col].nunique()
            null_count = gdf[col].isnull().sum()
            print(f"   {col}: {dtype} (å”¯ä¸€å€¼: {unique_count:,}, ç©ºå€¼: {null_count:,})")

            # é¡¯ç¤ºç¯„ä¾‹å€¼
            if dtype == 'object' and not gdf[col].dropna().empty:
                sample_values = gdf[col].dropna().unique()[:3]
                print(f"      ç¯„ä¾‹: {list(sample_values)}")

    # è½‰æ›åº§æ¨™ç³»çµ±è‡³ WGS84 (å¦‚æœéœ€è¦)
    if gdf.crs is None:
        # æ²’æœ‰åº§æ¨™ç³»çµ±è³‡è¨Šï¼Œå…ˆå‡è¨­ç‚ºå°ç£å¸¸ç”¨çš„ TWD97 TM2
        print("\nâš ï¸  è­¦å‘Š: æ²’æœ‰åº§æ¨™ç³»çµ±è³‡è¨Šï¼Œå‡è¨­ç‚º TWD97 TM2 (EPSG:3826)")
        gdf.crs = 'EPSG:3826'

    if str(gdf.crs) != 'EPSG:4326':
        print(f"\nğŸ”„ è½‰æ›åº§æ¨™ç³»çµ±å¾ {gdf.crs} è‡³ WGS84 (EPSG:4326)...")
        original_crs = gdf.crs
        try:
            gdf = gdf.to_crs('EPSG:4326')
            print(f"   âœ… æˆåŠŸè½‰æ›å¾ {original_crs} è‡³ EPSG:4326")
        except Exception as e:
            # å¦‚æœè½‰æ›å¤±æ•—ï¼Œå¯èƒ½éœ€è¦å˜—è©¦å…¶ä»–å°ç£å¸¸ç”¨åº§æ¨™ç³»çµ±
            print(f"   âš ï¸  ä½¿ç”¨ {original_crs} è½‰æ›å¤±æ•—ï¼Œå˜—è©¦ TWD97 TM2 (EPSG:3826)...")
            gdf.crs = 'EPSG:3826'
            gdf = gdf.to_crs('EPSG:4326')
            print(f"   âœ… æˆåŠŸè½‰æ›å¾ EPSG:3826 è‡³ EPSG:4326")

    # åŠ å…¥ CSV è³‡æ–™åˆ° GeoDataFrame
    if csv_data:
        print(f"\nğŸ”§ æ­£åœ¨åˆä½µ CSV è³‡æ–™åˆ° Shapefile...")

        # æª¢æŸ¥ CODEBASE æ¬„ä½
        if 'CODEBASE' in gdf.columns:
            print(f"   æ‰¾åˆ° CODEBASE æ¬„ä½")

            # ç‚ºæ¯ä¸€è¡ŒåŠ å…¥å°æ‡‰çš„ CSV è³‡æ–™
            matched_count = 0
            unmatched_count = 0

            for idx, row in gdf.iterrows():
                codebase = row['CODEBASE']
                if codebase in csv_data:
                    # å°‡ CSV è³‡æ–™åŠ å…¥åˆ° GeoDataFrameï¼Œä¸¦ç¢ºä¿è³‡æ–™å‹åˆ¥æ­£ç¢º
                    for key, value in csv_data[codebase].items():
                        # è½‰æ›è³‡æ–™å‹åˆ¥
                        if key in ['H_CNT', 'P_CNT']:  # æˆ¶æ•¸ã€äººå£æ•¸
                            gdf.at[idx, key] = int(value) if value is not None and not pd.isna(value) else 0
                        elif key == 'P_DEN':  # äººå£å¯†åº¦
                            gdf.at[idx, key] = float(value) if value is not None and not pd.isna(value) else 0.0
                        else:
                            gdf.at[idx, key] = value
                    matched_count += 1
                else:
                    unmatched_count += 1

            print(f"   âœ… æˆåŠŸåˆä½µ {matched_count} ç­†è³‡æ–™")
            if unmatched_count > 0:
                print(f"   âš ï¸  æœ‰ {unmatched_count} ç­†è³‡æ–™æ‰¾ä¸åˆ°å°æ‡‰çš„ CODEBASE")
        else:
            print(f"   âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ° CODEBASE æ¬„ä½ï¼Œç„¡æ³•åˆä½µ CSV è³‡æ–™")
            print(f"   å¯ç”¨æ¬„ä½: {[c for c in gdf.columns if c != 'geometry']}")

    # ç²¾ç°¡å±¬æ€§ï¼Œä¿ç•™éœ€è¦çš„æ¬„ä½
    print(f"\nğŸ”§ æ•´ç†å±¬æ€§æ¬„ä½...")
    original_columns = list(gdf.columns)
    print(f"   åŸå§‹æ¬„ä½æ•¸: {len([c for c in original_columns if c != 'geometry'])}")

    # æ±ºå®šè¦ä¿ç•™çš„æ¬„ä½
    keep_columns = ['geometry']

    # ä¿ç•™ TOWN æˆ– CODEBASE
    if 'TOWN' in gdf.columns:
        keep_columns.append('TOWN')
    if 'CODEBASE' in gdf.columns:
        keep_columns.append('CODEBASE')

    # ä¿ç•™ CSV åŠ å…¥çš„è³‡æ–™æ¬„ä½ï¼ˆåªä¿ç•™éœ€è¦çš„ï¼‰
    if csv_data:
        csv_fields = ['H_CNT', 'P_CNT', 'P_DEN']  # æˆ¶æ•¸ã€äººå£æ•¸ã€äººå£å¯†åº¦
        for field in csv_fields:
            if field in gdf.columns:
                keep_columns.append(field)

    # åªä¿ç•™éœ€è¦çš„æ¬„ä½
    gdf = gdf[keep_columns]

    # é‡æ–°å‘½åæ¬„ä½
    rename_map = {
        'H_CNT': 'household',           # æˆ¶æ•¸
        'P_CNT': 'population',          # äººå£æ•¸
        'P_DEN': 'population_density'   # äººå£å¯†åº¦
    }
    gdf = gdf.rename(columns=rename_map)

    # ç¢ºä¿è³‡æ–™å‹åˆ¥æ­£ç¢º
    if 'household' in gdf.columns:
        gdf['household'] = gdf['household'].fillna(0).astype(int)
    if 'population' in gdf.columns:
        gdf['population'] = gdf['population'].fillna(0).astype(int)
    if 'population_density' in gdf.columns:
        gdf['population_density'] = gdf['population_density'].fillna(0.0).astype(float)

    final_fields = [c for c in gdf.columns if c != 'geometry']
    print(f"   âœ… å·²æ•´ç†è‡³ {len(final_fields)} å€‹å±¬æ€§æ¬„ä½: {final_fields}")

    # ç§»é™¤ Z åæ¨™ï¼ˆé«˜åº¦ï¼‰ï¼Œåªä¿ç•™ X, Y åæ¨™
    print(f"\nğŸ”§ ç§»é™¤ Z åæ¨™ï¼Œåªä¿ç•™ç¶“ç·¯åº¦...")

    def remove_z_coordinate(geom):
        """ç§»é™¤å¹¾ä½•åœ–å½¢çš„ Z åæ¨™"""
        try:
            from shapely.ops import transform
            from shapely.geometry import Point, LineString, Polygon, MultiPolygon

            if geom is None:
                return geom

            def remove_z(x, y, z=None):
                return (x, y)

            return transform(remove_z, geom)
        except Exception as e:
            print(f"   è­¦å‘Š: ç§»é™¤ Z åæ¨™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return geom

    # å°æ‰€æœ‰å¹¾ä½•åœ–å½¢ç§»é™¤ Z åº§æ¨™
    gdf['geometry'] = gdf['geometry'].apply(remove_z_coordinate)

    print(f"   âœ… å·²ç§»é™¤ Z åæ¨™ï¼Œç¾åœ¨åªæœ‰ç¶“åº¦ (X) å’Œç·¯åº¦ (Y)")

    # é¡¯ç¤ºåº§æ¨™ç¯„åœ
    bounds = gdf.total_bounds
    print(f"\nğŸ“ åº§æ¨™ç¯„åœ:")
    print(f"   ç¶“åº¦ç¯„åœ: {bounds[0]:.6f} ~ {bounds[2]:.6f}")
    print(f"   ç·¯åº¦ç¯„åœ: {bounds[1]:.6f} ~ {bounds[3]:.6f}")

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # è½‰æ›ç‚º GeoJSON æ ¼å¼
    print(f"\nğŸ’¾ æ­£åœ¨è½‰æ›ç‚º GeoJSON...")

    try:
        # ç¢ºä¿è¼¸å‡ºç‚º 2D åº§æ¨™ï¼ˆç„¡ Z å€¼ï¼‰
        print("   ç¢ºä¿è¼¸å‡ºæ ¼å¼ç‚º 2D åº§æ¨™...")

        if compress:
            # å£“ç¸®è¼¸å‡º - ç„¡ç¸®æ’ï¼Œç„¡ç©ºæ ¼ï¼Œç¢ºä¿ç„¡ Z åæ¨™
            geojson_str = gdf.to_json(
                ensure_ascii=False,
                separators=(',', ':'),
                drop_id=True,
                to_wgs84=False  # é¿å…é¡å¤–åº§æ¨™è½‰æ›
            )
            print("   ä½¿ç”¨å£“ç¸®æ ¼å¼ï¼ˆ2D åº§æ¨™ï¼‰")
        else:
            # æ ¼å¼åŒ–è¼¸å‡º - æœ‰ç¸®æ’ï¼Œç¢ºä¿ç„¡ Z åæ¨™
            geojson_str = gdf.to_json(
                ensure_ascii=False,
                indent=2,
                drop_id=True,
                to_wgs84=False  # é¿å…é¡å¤–åº§æ¨™è½‰æ›
            )
            print("   ä½¿ç”¨æ ¼å¼åŒ–è¼¸å‡ºï¼ˆ2D åº§æ¨™ï¼‰")

        # æª¢æŸ¥ä¸¦ç§»é™¤å¯èƒ½æ®˜ç•™çš„ Z åæ¨™
        import json
        geojson_data = json.loads(geojson_str)

        def clean_coordinates(coords):
            """æ¸…ç†åº§æ¨™ï¼Œç¢ºä¿åªæœ‰ X, Y"""
            if isinstance(coords, list):
                if len(coords) > 0 and isinstance(coords[0], (int, float)):
                    # é€™æ˜¯åº§æ¨™é» [x, y] æˆ– [x, y, z]
                    return coords[:2]  # åªå–å‰å…©å€‹å€¼
                else:
                    # é€™æ˜¯åº§æ¨™é™£åˆ—ï¼Œéè¿´è™•ç†
                    return [clean_coordinates(coord) for coord in coords]
            return coords

        # æ¸…ç†æ‰€æœ‰ç‰¹å¾µçš„åº§æ¨™
        if 'features' in geojson_data:
            for feature in geojson_data['features']:
                if 'geometry' in feature and 'coordinates' in feature['geometry']:
                    feature['geometry']['coordinates'] = clean_coordinates(
                        feature['geometry']['coordinates']
                    )

        # é‡æ–°åºåˆ—åŒ–
        if compress:
            geojson_str = json.dumps(geojson_data, ensure_ascii=False, separators=(',', ':'))
        else:
            geojson_str = json.dumps(geojson_data, ensure_ascii=False, indent=2)

        # å¯«å…¥æª”æ¡ˆ
        print(f"   å¯«å…¥æª”æ¡ˆ: {output_path}")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(geojson_str)

        # é¡¯ç¤ºæª”æ¡ˆå¤§å°
        file_size = Path(output_path).stat().st_size
        if file_size > 1024 * 1024:
            size_str = f"{file_size / (1024 * 1024):.2f} MB"
        elif file_size > 1024:
            size_str = f"{file_size / 1024:.2f} KB"
        else:
            size_str = f"{file_size} bytes"

        print(f"âœ… è½‰æ›å®Œæˆï¼æª”æ¡ˆå¤§å°: {size_str}")

    except Exception as e:
        raise Exception(f"GeoJSON è½‰æ›å¤±æ•—: {e}")

    return gdf


def main():
    print("=" * 60)
    print("ğŸ—ºï¸  Shapefile è½‰ GeoJSON å·¥å…·")
    print("=" * 60)

    # æŒ‡å®š Shapefile è·¯å¾‘å’Œè¼¸å‡ºè·¯å¾‘
    shp_path = "data/basic_statistical_area/STAT/113å¹´12æœˆè‡ºåŒ—å¸‚çµ±è¨ˆå€äººå£çµ±è¨ˆ_æœ€å°çµ±è¨ˆå€/113å¹´12æœˆè‡ºåŒ—å¸‚çµ±è¨ˆå€äººå£çµ±è¨ˆ_æœ€å°çµ±è¨ˆå€_SHP"
    output_path = "data/basic_statistical_area/geojson/basic_statistical_area.geojson"

    # æŒ‡å®š CSV è·¯å¾‘
    csv_paths = {
        'population': 'data/basic_statistical_area/STAT/113å¹´12æœˆè‡ºåŒ—å¸‚çµ±è¨ˆå€äººå£çµ±è¨ˆ_æœ€å°çµ±è¨ˆå€/113å¹´12æœˆè‡ºåŒ—å¸‚çµ±è¨ˆå€äººå£çµ±è¨ˆ_æœ€å°çµ±è¨ˆå€.csv',
        'indicators': 'data/basic_statistical_area/STAT/113å¹´12æœˆè‡ºåŒ—å¸‚çµ±è¨ˆå€äººå£æŒ‡æ¨™_æœ€å°çµ±è¨ˆå€/113å¹´12æœˆè‡ºåŒ—å¸‚çµ±è¨ˆå€äººå£æŒ‡æ¨™_æœ€å°çµ±è¨ˆå€.csv'
    }

    print(f"ğŸ“‚ Shapefile è·¯å¾‘: {shp_path}")
    print(f"ğŸ“Š äººå£çµ±è¨ˆ CSV: {csv_paths['population']}")
    print(f"ğŸ“Š äººå£æŒ‡æ¨™ CSV: {csv_paths['indicators']}")
    print(f"ğŸ“ è¼¸å‡ºè·¯å¾‘: {output_path}")

    try:
        # æª¢æŸ¥è¼¸å…¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
        if not Path(shp_path).exists():
            raise Exception(f"æ‰¾ä¸åˆ° Shapefile è·¯å¾‘: {shp_path}")

        # æª¢æŸ¥ CSV æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        for key, csv_path in csv_paths.items():
            if not Path(csv_path).exists():
                raise Exception(f"æ‰¾ä¸åˆ° CSV æª”æ¡ˆ: {csv_path}")

        # åŸ·è¡Œè½‰æ›
        gdf = shp_to_geojson(
            shp_path=shp_path,
            output_path=output_path,
            csv_paths=csv_paths,
            compress=True  # å£“ç¸®è¼¸å‡º
        )

        print(f"\n" + "=" * 60)
        print("ğŸ‰ è½‰æ›ä½œæ¥­å®Œæˆï¼")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ è½‰æ›å¤±æ•—: {e}")
        print("\nå¯èƒ½åŸå› :")
        print("1. Shapefile è·¯å¾‘ä¸æ­£ç¢º")
        print("2. ç¼ºå°‘å¿…è¦æª”æ¡ˆ (.shp, .shx, .dbf)")
        print("3. æª”æ¡ˆç·¨ç¢¼å•é¡Œ")
        print("4. æ¬Šé™ä¸è¶³")


if __name__ == "__main__":
    main()